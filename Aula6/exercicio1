#!/usr/bin/python3
"""
Scraping
pip3 install requests
pip3 install beautifulsoup4

Da homepage do JN obter os varios links, titulos e tags das noticias
"""
import os
import sys
from getopt import getopt
import re
import requests
import shelve
from tqdm import tqdm
from bs4 import BeautifulSoup

r=requests.get("https://www.jn.pt")
soup=BeautifulSoup(r.text,features="html.parser")
pattern=r"jn.pt/\w+/"

news_dict=shelve.open('news_dict.db')


def visit_noticia(url):
    r=requests.get(url)
    soup=BeautifulSoup(r.text,features="html.parser")
    title=soup.find('h1',{'rel':'headline'})
    content=soup.find('div',{'class':'t-article-content-inner'})
    tags_section=soup.find('div',{'class':'t-article-funcs-tags-1'})
    tags=[]
    if tags_section:
        tags=[t.text for t in tags_section.findAll('li')]
    date=content.find("time")["content"]
    content.div.decompose()

    noticia={
        'title':title.text,
        'date':date,
        'content':content.text,
        'tags':tags
    }
    return noticia


noticias=[]
articles=soup.find_all("article")
for article in articles:
    header=article.h3
    if header is None:
        continue
    url=header.a
    if url is None:
        continue
    url_address=url["href"]
    title=article.h2.a.text
    if url_address.startswith("http"):
        continue
    noticias.append((title,url_address))

for noticia in tqdm(noticias):
    url='https://jn.pt'+ noticia[1]
    if url not in news_dict:
        noticia_parsed=visit_noticia(url)
        news_dict[url]=noticia_parsed 

news_dict.close()
#TODO: adicionar percorrer noticias relacionadas