#!/usr/bin/python3

import os
import sys
from getopt import getopt
import re
import requests
import shelve
from tqdm import tqdm
from bs4 import BeautifulSoup
import json


def visita_poemas(urlpoemas):
    for url in urlpoemas:
        r = requests.get(url)
        soup = BeautifulSoup(r.text, features="html.parser")
        painel = soup.find('div', {'class': 'panel panel-default'})
        if painel is None:
            continue
        else:
            body = painel.find('div', {'class': 'panel-body'})
        titulo = body.h2.text
        aux = body.find(
            'div', {'style': 'font-family: georgia;line-height: 30px;font-size: 16px'})
        text = aux.text
        conteudo = text.lstrip()
        paragrafos = re.findall(r"^.*", conteudo, re.MULTILINE)
        # limpeza do texto
        paragrafos = list(filter(''.__ne__, paragrafos))
        if '//' in paragrafos[:len(paragrafos)-1]:
            paragrafos = paragrafos[:len(paragrafos)-1]
        lista = []
        for paragrafo in paragrafos:
            if paragrafo.endswith('\r'):
                paragrafo = paragrafo[:-1]
            lista.append(paragrafo)
        #######################
        target_element = ""
        for l in lista:
            if ', in ' in l:
                target_element = l
        if ', in ' not in target_element:
            continue
        target_index = lista.index(target_element) + 1
        lista[:target_index]

        metadados = lista[target_index-1].split(', in ')
        if metadados[0] is not None:
            autor = metadados[0]
        else:
            autor = "N/A"
        if metadados[1] is not None:
            obra = metadados[1]
        else:
            obra = "N/A"
        poema = {
            'title': titulo,
            'obra': obra,
            'autor': autor,
            'content': lista[:-1]
        }
        with open("poemas/"+titulo+".json", "w") as fp:
            json.dump(poema, fp)
        fp.close()


def visita_autor(url):
    r = requests.get(url)
    soup = BeautifulSoup(r.text, features="html.parser")
    urls = []
    poemas = soup.find_all('div', {'class': 'panel panel-default'})
    for poema in poemas:
        body = poema.find('div', {'class': 'panel-body'})
        aux = body.find('div', {'style': 'float:right'})
        url = aux.a["href"]
        urls.append(url)
    return urls


r = requests.get("https://citador.pt/poemas/autores")
soup = BeautifulSoup(r.text, features="html.parser")

autores = soup.find_all('div', {'class': 'panel panel-default'})
for autor in autores:
    aux = autor.find('div', {'style': 'float:right'})
    url = aux.a["href"]
    urlpoemas = visita_autor(url)
    visita_poemas(urlpoemas)
